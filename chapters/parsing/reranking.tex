\documentclass[../../document.tex]{subfiles}

\begin{document}
    \section{Reranking}\label{sec:reranking}
    This section focuses on a refinement procedure to pick one final constituent tree among a sequence of \(n \in \DN_+\) parses.
    A \deflab{reranking} process is an empirical prediction that assesses a previous empirical prediction by assigning a new confidence value to each label in conjunction with its prior confidence value.
    In the case of reranking in the field of parsing, it takes the predicted sequence of \(n\) best parses, each complemented with the score of the parse, and computes a new score for each parse tree; we use the best among these scores to pick the final parse tree.
    The concept of reranking has its tradition in information retrieval and recommender systems. Both are disciplines in machine learning that focus on finding matching information resources for queries or suggestions for individuals, respectively.
    Reranking is used in this context to refine matches obtained in a query by a prior prediction model \citep{carbonell1998use,adomavicius2009toward}.

    Formally, we define a \emph{reranking process} as follows:
        Let \(Y\) be a set of labels and \(\mathcal{C}\) a set of confidence values.
        A reranker is a function \(\psi \colon Y \times \mathcal{C} \to \mathcal{C}\) that assigns a confidence value to each pair of a label and \emph{prior confidence value}.
    Often, only a tiny fraction \(\hat{Y} \subseteq Y\) of the set of labels, called \emph{search space}, is considered for the reranking process.
    In the case of reranking in parsing, the search space is the collection of constituent trees within an \(n\) best sequence, and the reranking process is used to find the highest scoring among those.
    Consider a sequence of \(n\) labels \((t_1, \ldots, t_n) \in Y^n\) and \(\phi \colon Y \to C\) an assignment of prior confidence values.
    We call a \deflab{\(\psi\)-pick among \(t_1 \ldots t_n\)} the label that maximizes the reranker \(\psi\)'s confidence value, that is, \(
        t \in \argmax_{\hat{t} \in \hat{Y}} \psi(\hat{t}, \phi(\hat{t}))
    \) where \(\hat{Y} = \{t_i \mid i \in [n]\}\) is the search space.
    \Cref{sec:references:reranking} gives a summary of the literature for reranking procedures applied in the field of parsing constiutent trees.

    In this work, we rerank constituent trees using the \defabrv{discontinuous data-oriented parsing}{disco-dop} formalism.
    Disco-dop has been characterized as an instance of \abrv{lcfrs} with latent annotations \citep[Section~4]{Cra11} and hence also hybrid grammars \citep[Section~8.5.1]{Geb20}.
    The formalism was introduced by \citet{Cra11} as a generalization of data-oriented parsing \citep{Bod92} to the case of discontinuous constituent structures.
    Such a grammars consist of constituent tree fragments with substitution sites at leaves that carry nonterminal symbols.
    To accommodate discontinuities, each tree fragment is complemented by an \abrv{lcfrs} composition that restricts the substitution in consideration of the terminal symbols occurring in the tree fragments.
    \Cref{ex:dop} shows an example of a disco-dop grammar.
    Following \citet{San11}, \citet{Cra11}, we use the \emph{double dop} extraction approach for discontinuous constituent trees.
    It extracts rules for each constituent tree fragment in the training set that occurs at least twice.
    We restrict the fragments such that they do not include tokens from the constituent trees but end at the \abrv{pos} symbols.
    We estimate probabilistic weights for each rule by conditioning on the \abrv{lhs} nonterminal/root constituent symbol.
    However, in contrast to the coarse-to-fine approach described by \citet{Cra11}, we do not define a filtering mechanism based on the parse chart from the previous part of the parsing pipeline but view the disco-dop reranking as a completely separate process for weighting each single constituent tree in an \(n\) best parsing sequence.
    Therefore, we augment the usual parsing procedure for \abrv{lcfrs} (which can be used for disco-dop) to only produce derivations for the input constituent tree by matching its nodes.
    Moreover, we slightly diverge from the weight structure that we use for parsing with the supertags:
        In this case, we do not use the Viterbi-equivalent sum and maximum operations with logarithms of probabilistic values but the probabilistic product and sum operations.
    These augmentations are straightforward, and we refrain from further elaborating on the parsing process.

    \begin{example}\label{ex:dop}
        \Cref{fig:ex:dop} shows four rules of a disco-dop grammar that consist of fragments in the tree to the left.
        The rules are in the notation used by \citet{CraSchBod16}.
        They denote them similarly to \abrv{lcfrs}:
            Each leaf that is a substitution site is complemented with a sequence of variables, and each leaf that is a terminal has an index, such that each of these objects uniquely occurs within each rule.
            A composition below the root node indicates how terminals may be concatenated by the rules using the variables and indices from the leaves.
            The compositions are tuples, allowing discontinuities in the same sense as in \abrv{lcfrs}.
        The illustrated rules can produce the constituent structure with two different derivations, one starting with the upper left rule and one with the bottom right one.
        The following hybrid grammar rules are equivalent to the above notation: \begin{align*}
            \cn{sbar} &\to (\x_1^1 \, \x_2^1 \, \x_1^2)\;(\cn{sbar} (\cn{s} (x_1, x_2)))\;(\cn{vp}_2, \cn{np}) \\
            \cn{np} &\to (\cn{pt} \, \cn{nn})\;(\cn{np} (\cn{pt}, \cn{nn})) \\
            \cn{vp}_2 &\to (\cn{wrb}, \cn{vbn} \, \cn{rp})\;(\cn{vp} (\cn{wh}(\cn{wrb}),\cn{vbn},\cn{np}(\cn{rp}))) \\
            \cn{sbar} &\to (\x_1^1 \, \cn{pt} \, \cn{nn} \, \x_1^2)\;(\cn{sbar} (\cn{s} (\cn{vp}_2(x_1),\cn{np}(\cn{pt}, \cn{nn}))))\;(\cn{vp}_2)
        \end{align*}
    \end{example}

    \begin{figure}
        \null\hfill
        \subfile{../figures/example-constituents.tex}
        \hspace{1cm}
        \subfile{figures/example-dop.tex}
        \hfill\null
        \caption{\label{fig:ex:dop}
            The running example constituent tree and four rules of a disco-dop grammar with derivations for the constituent structure and its sequence of \abrv{pos} tags.}
    \end{figure}
\end{document}