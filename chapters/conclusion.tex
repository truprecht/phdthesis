\documentclass[../document.tex]{subfiles}

\begin{document}
    \chapter{Conclusion and Future Work}
    This chapter concludes the thesis with a summary of our contributions and results and gives some pointers for future work.

    \Cref{sec:extraction} describes two extraction procedures for lexicalized grammars from discontinuous constituent treebanks.
    Both of them make no assumptions about the constituent treebanks by themselves, but the section also introduces extensions to utilize lexical head assignments in the extraction.
    The first procedure is concerned exclusively with \abrv{lcfrs} as grammar formalism, and the second is used to extract either \abrv{lcfrs}/\abrv{dcp} hybrid grammars or \abrv{dcp}.
    \Cref{sec:parsing} describes a parsing framework that exploits the extracted lexical grammar rules:
        A discriminative classifier predicts a small number of lexical rules per input sentence position, which are then used to parse the sentence with a small grammar; the prediction step is called supertagging.
    The section also introduces an algorithm for parsing with \abrv{dcp} grammar instances, which has not seen application in the natural language processing community before.
    We experimented with three discontinuous constituent treebanks and two neural network architectures to implement the prediction.
    \Cref{sec:gridsearch,sec:gridsearch:other} show our vast experiments to find feasible parameters for extracting and parsing with supertags.
    Using the parameters, we are able to obtain results among the state-of-the-art in the field of discontinuous parsing.
    Compared to parsers relying on statistical grammar formalisms, we achieve more accurate results while being magnitudes faster.
    
    We show the number of extracted supertags for varying extraction parameters in \cref{sec:gridsearch,sec:gridsearch:other}.
    Compared to the sets of grammar rules extracted for statistical parsing, these are quite small.
    For instance, \citet[cf.\@ Figure 7.4]{Geb20} reports grammars ranging from 60 thousand to 50 million rules depending on the grade of refinement; the smallest ones have no practical relevance, however, as parsing with them is too inaccurate.\footnote{
        \Citet{CraSchBod16} do not list the number of extracted fragments in their experiments, but from the results of \citet{San11}, we suppose they are also in the order of millions.
    }
    For the same treebank, we used a set of 2075 supertag blueprints in our final models.
    \Citet{Geb20} put the argument for the interpretability of grammar-based parsing for natural language into question, as the instances extracted from treebanks tend to grow vast.
    We suggest that extracting supertag blueprints is an appropriate measure for extracting compact and controllable grammars, and their argument does not hold to it.
    \Citet[][in Table 1]{Bla18} report they extract two sets of \abrv{tag} supertags from the treebank, a small set with 2516 and a full set with 3426 supertags; the set we use in our final model is smaller than these two.
    However, they achieve higher accuracy in the prediction of supertags.

    While searching for viable hyperparamters in \cref{sec:gridsearch,sec:gridsearch:other} we noted some trends worth mentioning.
    We experimented with six different guide constructors that determine the structure of the lexicalized grammar derivations. Aside from two of them, namely the near and least guide constructors, we could achieve similar prediction and parsing accuracy for models trained using supertag blueprints with each guide constructor.
    Even with supertag blueprints extracted with the least or near guide constructor, the differences in parsing f-score were around 4 points among each model; we expected much greater margins before conducting the experiments.
    However, the experiments show notable differences in the number of extracted supertag blueprints for each extraction parameter.
    Specifically, we show the smallest sets of supertags in a new series of experiments that exclusively use definite clause programs as grammar formalism in \cref{sec:gridsearch:dcp}.
    The formalism allows us to reduce the set of nonterminal symbols further and omits the string composition function that appears in hybrid grammar rules.
    Even with such configurations that achieve very small sets of extracted supertag blueprints, most experiments show only marginal differences in parsing accuracy.
    On the other hand, experiments with the constituent symbol clusters we used to construct coarse nonterminals in \cref{sec:gridsearch:coarse} show worse parsing but slightly higher supertag prediction accuracy.
    Further research could find more appropriate clusters to reduce the set of nonterminals while maintaining the parsing accuracy.

    We also want to underline the set of experiments with the head guide constructor added in this work.
    Despite that the sets of supertag blueprints tend to be (much) larger than with the strict guide constructor, they achieve similar parsing accuracy in the end; in the case of \abrv{dptb}, we even decide for the head guide constructor for the supervised model.
    We suggest these experiments are worth mentioning because the extraction process utilizing the lexical head assignment is more akin to the strategy to extract tree-adjoining grammar supertags as done, for instance, by \cite{Kaeshammer2012GermanAE, Bla18}.
    Further research could investigate the similarities and differences between these approaches to find improvements.
    We chose to abstain from those investigations to focus on treebank-independent approaches for the extraction.

    The experiments also show that our attempt at improving the parsing accuracy with a reranking procedure fails.
    We chose discontinuous data-oriented parsing as a formalism for the task for two reasons.
        Firstly, we chose a grammar formalism because we did not want to introduce some other discriminative classifier on top of the supertagging prediction, as this would undermine the interpretability of the parsing approach.
        Secondly, \citet{CraSchBod16} already showed that this formalism can be used to improve the results of parsing with linear context-free rewriting systems.
    But the oracle f-scores in \cref{sec:gridsearch:reranking} suggest a potential for improvement by choosing among one of \(n\) best constituent trees found by parsing with the predicted supertags.
    We suppose a viable reranking approach can be found in further research.

    Our approach is a viable compromise between the advantages of parsing with robust discriminative classifiers and the merits of grammar-based parsers.
    Even with exclusively supervised models, we achieve higher accuracy scores in less parse time than state-of-the-art parsers solely based on grammar formalisms.
    Supertagging also has the benefit of using pre-trained models utilizing knowledge that is not part of the treebanks used to extract the grammar rules.
    With said models, we can parse as accurately as other stat-of-the-art parsers for discontinuous constituents.
    In recent years, some parts of the \abrv{nlp} community have written off parsing with grammar formalisms as being too inaccurate and slow (cf. \citealp{StaSte20} in Section 1, \citealp{zhang2020survey} in Section 10).
    We tend to agree regarding approaches that solely rely on grammar formalisms.
    But we suggest this work gives enough evidence that these formalisms can act as a solid foundation for parsers that combine them with strong machine learning models.
\end{document}