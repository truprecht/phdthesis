\documentclass[../../document.tex]{subfiles}

\begin{document}
    \section{Hyperparameter Search in  \abrv{Dptb} and \abrv{Tiger}}\label{sec:gridsearch:other}
    To tune the hyperparameters for the experiments with \abrv{dptb} and \tiger{}, we use a radically reduced set of values compared to the previous section.
    We omit hyperparamter values if that we think are unrealistic to preduce relevant results.
    Specifically, we set the following restrictions:
    \begin{itemize}
        \item we omit the vanilla, near and least guide constructors (leaving 3 options),
        \item we omit the vanilla nonterminal constructor and the coarse nonterminal constructor with auxiliary table (leaving 2 options), 
        \item we only use right branching binarization in case of the strict guide constructor, and the head guide constructor in tandem with head-inward transformation,
        \item we use the Markovization parameters \(h = 0\) and \(v \in \{1,2\}\) (leaving two options),
        \item in case of \abrv{dcp} supertags, we only investigate the strict guide constructor with nof and disc extensions for a small amount (we choose 1 or 2 samples as explained in the discussion of the results) of combinations of nonterminal and guide constructors and Markovization parameters that performed best with \abrv{lcfrs} supertags.
    \end{itemize}

    We explore the remaining grid of configurations completely with hybrid grammar and \abrv{dcp} supertags, which yields a total of $3 \cdot 2 \cdot 2 = 12$ experiments per treebank and prediction model with \abrv{lcfrs} supertags and 2--4 additional experiments with \abrv{dcp} supertags per model.
    Each of the following two subsections will guide through the experiments with one treebank in the same fashion as in the experiments with \negra{} in the previous section.

    \subsection{\abrv{Dptb}}
    \Cref{tbl:experiments:dptb} shows the results for the hybrid grammar supertag prediction and parsing accuracies for each experiment in the grid search for \abrv{dptb}
    Each experiment was conducted using the supervised and the pretrained prediction model.
    
    \begin{table}
        \caption{\label{tbl:experiments:dptb:size}
        Number of extracted supertag blueprints from the training portion ($N$) and number of extracted supertag blueprints in the dev portion that do not appear in the training portion ($\overline{N}$) using the \dptb{} treebank.
        }
        \centering
        \setlength{\tabcolsep}{4pt}
        \vspace{.2cm}
        \begin{tabular}{lc|rr|rr|rr}
            \toprule
             &        & \multicolumn{2}{c|}{strict} & \multicolumn{2}{c|}{dependent} & \multicolumn{2}{c}{head}  \\
 nont.   &\(v\)   & $N$ & $\overline{N}$ & $N$ & $\overline{N}$ & $N$ & $\overline{N}$ \\ \hline
  classic & \(1\)  & 2403 &  28 &  4295 &  51 &  4374 &  66  \\
  classic & \(2\)  & 5627 &  64 &  9152 & 123 &  8544 & 137  \\
  coarse  & \(1\)  & 1778 &  22 &  3431 &  41 &  3946 &  61  \\
  coarse  & \(2\)  & 3780 &  44 &  6853 &  80 &  7030 & 108  \\
    \bottomrule
        \end{tabular}
    \end{table}

    \begin{table}
        \caption{\label{tbl:experiments:dptb}
        Parsing f1 score, accuracy of predicted supertag blueprints, parse time ($t$) and and number of parse fails ($\lightning$) in \abrv{dptb}'s development set for both prediction models (Mod.), combinations of guide and nonterminal constructors as well as vertical Markovization context ($v$) for the used rank transformation.
        }
        \centering
        \setlength{\tabcolsep}{4pt}
        \vspace{.2cm}
        \begin{tabular}{llc|rrrr|rrrr|rrrr}
            \toprule
  &             &        & \multicolumn{4}{c|}{strict} & \multicolumn{4}{c|}{dependent} & \multicolumn{4}{c}{head}  \\
Mod. &     nont.   &\(v\)   & f1 & acc. & $t$ & $\lightning$ & f1 & acc. & $t$ & $\lightning$ & f1 & acc. & $t$ & $\lightning$ \\ \hline
pret. &     classic & \(1\)  & 90.53 & 0.91 & 10.01 & 3 & 93.60 & 0.90 & 10.61 & 14 & 94.28 & 0.91 & 11.99 & 9 \\
pret. &     classic & \(2\)  & 93.95 & 0.88 & 9.97 & 24 & 93.02 & 0.87 & 10.75 & 61 & 92.93 & 0.88 & 11.04 & 42 \\
pret. &     coarse  & \(1\)  & 90.21 & 0.91 & 10.12 & 1 & 93.65 & 0.90 & 14.76 & 9 & 94.57 & 0.92 & 10.93 & 4 \\
pret. &     coarse  & \(2\)  & 94.30 & 0.89 & 10.51 & 13 & 92.97 & 0.87 & 10.80 & 54 & 93.71 & 0.88 & 24.71 & 19 \\
\midrule
sup. & classic & \(1\)  & 86.47 & 0.87 & 11.82 & 1 & 89.20 & 0.85 & 18.08 & 10 & 89.60 & 0.86 & 14.22 & 3 \\
sup. & classic & \(2\)  & 89.31 & 0.81 & 11.75 & 28 & 88.75 & 0.80 & 15.50 & 54 & 89.39 & 0.82 & 14.36 & 31 \\
sup. & coarse  & \(1\)  & 85.54 & 0.86 & 13.30 & 0 & 89.21 & 0.85 & 21.14 & 3 & 89.48 & 0.86 & 16.50 & 0 \\
sup. & coarse  & \(2\)  & 89.97 & 0.82 & 15.01 & 5 & 88.87 & 0.80 & 15.95 & 38 & 89.76 & 0.82 & 15.15 & 15 \\
    \bottomrule
        \end{tabular}
    \end{table}

    The trends for the parsing quality deviate from those that we observed in the German \negra{} treebank.
    With both models, the parsing quality is notably better with vertical Markovization context in the case of the strict guide.
    However, in all cases with $v=2$, the number of parse fails increases, and the quality of supertag predictions decreases notably compared to the same configuration but with $v=1$.
    With the pre-trained model, the parsing quality decreases with $v=2$ and the other two guide constructors.
    In the case of the supervised model, there is no clear trend. In those cases, the differences are either minor or reversed.
    Generally, the presented parsing qualities with the supervised model are quite close, except those with the strict guide and $v=1$.
    However, we see two combinations that stand out from the remainder:
    \begin{compactitem}
        \item the strict guide and coarse nonterminal constructors with $v=2$, and
        \item the head guide and coarse guide constructor with $v=1$.
    \end{compactitem}
    These two achieve the best parsing qualities with the pretrained model, with the supervised model the first case reports the best parsing quality as well.
    While the number of parse failures is rather high in the first case using the supervised model, the second gives a good compromise between parsing and prediction quality as well as a low number of parse failures with both prediction models.

    \begin{table}
        \caption{\label{tbl:experiments:dptb:dcp}
        Number of extracted supertag blueprints ($N$), number of supertag blueprints that appear in the developement but not in the training portion, ($\overline{N}$), parsing f1 score, accuracy of predicted \abrv{dcp} supertag blueprints, parse time ($t$) and number of parse fails ($\lightning$) in \abrv{dptb}'s development set for both prediction models (Mod.), combinations of guide and nonterminal constructors as well as vertical Markovization context ($v$) for the used rank transformation.
        }
        \centering
        \setlength{\tabcolsep}{4pt}
        \vspace{.2cm}
        \begin{tabular}{lllc|cc|rrrr}
            \toprule
Mod. &  guide &   nont.   &\(v\)   & $N$ & $\overline{N}$ & f1 & acc. & $t$ & $\lightning$ \\ \hline \rowcolor{black!10}
pret. & strict (hg) &  coarse       & \(2\) & 3780 & 44 & 94.30 & 0.89 & 10.51 & 13  \\\hline
pret. & strict      &  coarse-disc  & \(2\) & 3723 & 41  & 94.30 & 0.89 & 11.09 & 8  \\
pret. & strict      &  coarse-nof   & \(2\) & 3432 & 36 & 94.40 & 0.89 & 10.38 & 8  \\ \hline\rowcolor{black!10}
pret. & head  (hg)  &  coarse       & \(1\) & 3946 & 61 & 94.57 & 0.92 & 10.93 & 4  \\\hline
pret. & head        &  coarse-disc  & \(1\) & 3824 & 60 & 93.95 & 0.91 & 16.86 & 6  \\
pret. & head        &  coarse-nof   & \(1\) & 3564 & 57 & 94.04 & 0.92 & 19.45 & 9  \\
\midrule \rowcolor{black!10}
sup. & strict (hg) &  coarse        & \(2\) & 3780 & 44 & 89.97 & 0.82 & 15.01 & 5  \\\hline
sup. & strict    &  coarse-disc     & \(2\) & 3723 & 41 & 89.74 & 0.82 & 14.35 & 6  \\
sup. & strict     &  coarse-nof     & \(2\) & 3432 & 36 & 89.86 & 0.82 & 18.83 & 4  \\\hline\rowcolor{black!10}
sup. & head (hg)  &  coarse         & \(1\) & 3946 & 61 & 89.48 & 0.86 & 16.50 & 0  \\\hline
sup. & head      &  coarse-disc     & \(1\) & 3824 & 60 & 89.25 & 0.86 & 30.92 & 9  \\
sup. & head       &  coarse-nof     & \(1\) & 3564 & 57 & 88.95 & 0.86 & 34.98 & 15  \\
    \bottomrule
        \end{tabular}
    \end{table}

    \begin{table}
        \caption{\label{tbl:experiments:dptb:k}
        Parsing f1 score, parse time ($t$) and number of parse fails ($\lightning$) in \dptb{}'s development set for both prediction models (Mod.) and combinations of number of supertags ($k$) and confidence interval ($\beta$) used for parsing.
        }
        \centering
        \setlength{\tabcolsep}{4pt}
        \vspace{.2cm}
        \begin{tabular}{cr|rrr|rrr|rrr}
            \toprule
&     &       \multicolumn{3}{c|}{$k = 10$} & \multicolumn{3}{c|}{$k = 20$} & \multicolumn{3}{c}{$k = 50$} \\
Mod. &  $\beta$  & f1 & $t$ & $\lightning$ & f1 & $t$ & $\lightning$ \\ \hline
pret. & 0.1  & 94.82 & 4.4 & 1 & 94.81 & 2.0 & 1 & 94.81 & 1.6 & 0 \\
pret. & 0.5  & 94.86 & 1.5 & 1 & 94.85 & 1.7 & 1 & 94.83 & 1.8 & 2 \\
pret. &   2  & 94.87 & 1.5 & 1 & 94.84 & 1.6 & 2 & 94.76 & 2.8 & 4 \\
pret. &   5  & 94.85 & 1.7 & 2 & 94.78 & 1.8 & 4 & 94.70 & 1.7 & 7 \\
\midrule 
sup. & 0.1  & 90.90 & 2.6 & 1 & 90.91 & 2.2 &  0 & 90.87 & 1.9 &  0 \\
sup. & 0.5  & 90.90 & 2.2 & 1 & 90.88 & 2.6 &  1 & 90.84 & 5.1 &  1 \\
sup. &   2  & 90.96 & 2.2 & 3 & 90.74 & 4.8 &  8 & 90.80 & 6.9 &  8 \\
sup. &   5  & 90.71 & 2.6 & 9 & 90.55 & 5.4 & 13 & 90.56 & 7.0 & 14 \\
    \bottomrule
        \end{tabular}
    \end{table}

    We repeat the experiments with \abrv{dcp} supertags with each nof and disc extensions for the nonterminals; the results are shown in \cref{tbl:experiments:dptb:dcp}.
    The table shows the previous results with hybrid grammar supertags for comparison in rows with gray backgrounds.
    This set of experiments shows only small differences in parsing quality.
    We suppose they are negligible and decide on the single most promising combination for each model via the highest f1 score and least amount of parse fails and end up with
    \begin{compactitem}
        \item the head guide and coarse nonterminal constructors, no added vertival Markovization context ($v=1$) and hybrid grammar supertags for the pre-trained model, and
        \item the strict guide and coarse nonterminal constructors, vertical Markovization context \(v=2\) and hybrid grammar supertags for the supervised model.
    \end{compactitem}
    Finally, we train models using these hyperparameters and conduct a small grid search for the two parsing parameters \(k\) and \(\beta\). The results are shown in \cref{tbl:experiments:dptb:k}.
    We pick the values according to the greatest f-score and settle with \(k=10\) and \(\beta=2\) for both models.

    \subsection{\abrv{Tiger}}
    \begin{table}
        \caption{\label{tbl:experiments:tiger:size}
        Number of extracted supertag blueprints from the training portion ($N$) and number of extracted supertag blueprints in the dev portion that do not appear in the training portion ($\overline{N}$) using the \tiger{} treebank.
        }
        \centering
        \setlength{\tabcolsep}{4pt}
        \vspace{.2cm}
        \begin{tabular}{lc|rr|rr|rr}
            \toprule     
            &        & \multicolumn{2}{c|}{strict} & \multicolumn{2}{c|}{dependent} & \multicolumn{2}{c}{head}  \\
  nont.   &\(v\)   & $N$ & $\overline{N}$ & $N$ & $\overline{N}$ & $N$ & $\overline{N}$ \\ \hline
   classic & \(1\)  & 3065 &  83 &  5468 & 180 &  6033 & 234  \\
   classic & \(2\)  & 8113 & 221 & 13383 & 422 & 12201 & 421   \\
   coarse  & \(1\)  & 2075 &  47 &  4160 & 130 &  5564 & 219      \\
   coarse  & \(2\)  & 5197 & 116 &  9896 & 296 & 10652 & 377  \\
    \bottomrule
        \end{tabular}
    \end{table}
    \begin{table}
        \caption{\label{tbl:experiments:tiger}
        Parsing f1 score, accuracy of predicted supertag blueprints, parse time ($t$) and and number of parse fails ($\lightning$) in \tiger{}'s development set for both prediction models (Mod.), combinations of guide and nonterminal constructors as well as vertical Markovization context ($v$) for the used rank transformation.
        }
        \centering
        \setlength{\tabcolsep}{4pt}
        \vspace{.2cm}
        \begin{tabular}{llc|rrrr|rrrr|rrrr}
            \toprule
         &    &        & \multicolumn{4}{c|}{strict} & \multicolumn{4}{c|}{dependent} & \multicolumn{4}{c}{head}  \\
    Mod. & nont.   &\(v\)   & f1 & acc. & $t$ & $\lightning$ & f1 & acc. & $t$ & $\lightning$ & f1 & acc. & $t$ & $\lightning$ \\ \hline
    pret. & classic & \(1\)  & 92.25 & 0.91 & 51.27 & 7 & 91.84 & 0.90 & 54.69 & 49 & 92.02 & 0.91 & 54.61 & 28 \\
    pret. & classic & \(2\)  & 91.25 & 0.87 & 53.60 & 75 & 89.39 & 0.86 & 57.06 & 214 & 90.28 & 0.87 & 57.94 & 133 \\
    pret. & coarse  & \(1\)  & 92.75 & 0.92 & 50.58 & 1 & 92.06 & 0.90 & 54.43 & 21 & 92.11 & 0.91 & 54.80 & 7 \\
    pret. & coarse  & \(2\)  & 91.93 & 0.87 & 52.10 & 32 & 90.06 & 0.86 & 55.40 & 165 & 90.34 & 0.87 & 56.19 & 120 \\
    \midrule
    sup. & classic & \(1\)  & 85.85 & 0.84 & 33.96 & 1 & 86.36 & 0.83 & 36.28 & 19 & 85.46 & 0.84 & 40.41 & 5 \\
    sup. & classic & \(2\)  & 84.35 & 0.76 & 34.60 & 85 & 82.38 & 0.74 & 37.08 & 267 & 84.16 & 0.77 & 37.54 & 127 \\
    sup. & coarse  & \(1\)  & 85.76 & 0.84 & 32.82 & 0 & 85.51 & 0.82 & 41.29 & 9 & 85.49 & 0.84 & 36.33 & 1 \\
    sup. & coarse  & \(2\)  & 85.43 & 0.77 & 36.65 & 34 & 83.30 & 0.75 & 36.99 & 198 & 83.78 & 0.76 & 36.30 & 100 \\
    \bottomrule
        \end{tabular}
    \end{table}

    The results reported in \cref{tbl:experiments:tiger} for the \tiger{} treebank are very similar to those in \negra{}.
    With the pre-trained model, we see a clear trend that the values for the strict guide constructor consistently outperform those of the other two in terms of higher parsing quality or fewer parse fails.
    The supervised model also reproduces this trend, except for one instance (cf.\@ f1 score using the dependent guide and classic nonterminal constructor, $v=1$, but with significantly more parse fails).
    We pick the following combination for each model:
    \begin{compactitem}
        \item strict guide and coarse nonterminal constructors, no added vertival Markovization context ($v=1$) and hybrid grammar supertags for the pretrained model, and
        \item strict guide and classic nonterminal constructors, no added vertival Markovization context ($v=1$) and hybrid grammar supertags for the supervised model.
    \end{compactitem}

    \begin{table}
        \caption{\label{tbl:experiments:tiger:dcp}
        Number of extracted supertag blueprints ($N$), number of supertag blueprints that appear in the developement but not in the training portion, ($\overline{N}$), parsing f1 score, accuracy of predicted \abrv{dcp} supertag blueprints, parse time ($t$) and number of parse fails ($\lightning$) in \abrv{dptb}'s development set for both prediction models (Mod.), combinations of guide and nonterminal constructors as well as vertical Markovization context ($v$) for the used rank transformation.
        }
        \centering
        \setlength{\tabcolsep}{4pt}
        \vspace{.2cm}
        \begin{tabular}{lllc|cc|rrrr}
            \toprule
Mod. &  guide &   nont.   &\(v\)  & $N$ & $\overline{N}$  & f1 & acc. & $t$ & $\lightning$ \\ \hline \rowcolor{black!10}
pret. & strict (hg) &  coarse & \(1\)     & 2075 & 47 & 92.75 & 0.92 & 50.58 & 1  \\\hline
pret. & strict    &  coarse-disc & \(1\)  & 1875 & 38 & 92.70 & 0.92 & 53.09 & 1  \\
pret. & strict     &  coarse-nof & \(1\)  & 1466 & 33 & 92.73 & 0.92 & 54.37 & 2  \\
\midrule \rowcolor{black!10}
sup. & strict (hg) &  coarse & \(1\)     & 2075 & 47 & 85.76 & 0.84 & 32.82 & 0  \\\hline
sup. & strict    &  coarse-disc & \(1\)  & 1875 & 38 & 85.61 & 0.84 & 33.70 & 0  \\
sup. & strict     &  coarse-nof & \(1\)  & 1466 & 33 & 85.59 & 0.84 & 39.86 & 0  \\
    \bottomrule
        \end{tabular}
    \end{table}

    \begin{table}
        \caption{\label{tbl:experiments:tiger:k}
        Parsing f1 score, parse time ($t$) and number of parse fails ($\lightning$) in \tiger{}'s development set for both prediction models (Mod.) and combinations of number of supertags ($k$) and confidence interval ($\beta$) used for parsing.
        }
        \centering
        \setlength{\tabcolsep}{4pt}
        \vspace{.2cm}
        \begin{tabular}{cr|rrr|rrr|rrr}
            \toprule
&      &      \multicolumn{3}{c|}{$k = 10$} & \multicolumn{3}{c|}{$k = 20$} & \multicolumn{3}{c}{$k = 50$} \\
Mod. &  $\beta$  & f1 & $t$ & $\lightning$ & f1 & $t$ & $\lightning$ \\ \hline
pret. & 0.1  & 92.78 & 3.6 & 1 & 92.80 & 4.8 & 0 & 92.80 & 4.8 & 0 \\
pret. & 0.5  & 92.76 & 3.1 & 1 & 92.79 & 3.1 & 0 & 92.78 & 6.7 & 0 \\
pret. &   2  & 92.77 & 3.4 & 1 & 92.81 & 3.4 & 0 & 92.80 & 3.9 & 0 \\
pret. &   5  & 92.77 & 4.9 & 1 & 92.82 & 3.5 & 1 & 92.78 & 2.8 & 3 \\
\midrule 
sup. & 0.1  & 87.46 & 4.2 & 1 & 87.50 & 3.2 & 0 & 87.48 & 5.6 & 0 \\
sup. & 0.5  & 87.54 & 6.0 & 1 & 87.57 & 2.6 & 0 & 87.54 & 3.6 & 1 \\
sup. &   2  & 87.54 & 5.5 & 2 & 87.57 & 8.3 & 1 & 87.52 & 3.5 & 2 \\
sup. &   5  & 87.49 & 5.5 & 4 & 87.46 & 3.3 & 6 & 87.42 & 5.0 & 7 \\
    \bottomrule
        \end{tabular}
    \end{table}

    Similar to the same set of experiments in \abrv{dptb}, the values show almost no difference using \abrv{dcp} supertags with the two nonterminal extensions, except for a slight deterioration in terms of lower parsing accuracy and higher parsing time.
    Again, we suppose it is negligible and settle with the hybrid grammar configuration for the supervised and pre-trained model.
    Lastly, we train supertag prediction models using these sets of parameters and conduct a small grid search over the parameters for the parsing procedure, $k$ and $\beta$.
    \cref{tbl:experiments:tiger:k} lists the results for each tested combination and both models.
    The values are distributed in relatively small ranges for each of the two models.
    We decide to pick simply via the greatest f1-scores and least values for \(k\) and \(\beta\) and end up with \(k=20\) and \(\beta=0.1\) for the pretrained model, and \(k=20\) and \(\beta=0.5\) for the supervised model.
\end{document}