\documentclass[../document.tex]{subfiles}


\begin{document}
    \chapter{Parsing via Supertagging}\label{chp:parsing}
    This chapter describes a unified framework of a supertagging-based parsing process based on the grammar formalisms explained in the previous chapter.
    The parsing process is divided into three consecutive steps, plus one optional refinement procedure (reranking) as illustrated in \cref{fig:parsing:overview}:
    \begin{enumerate}
        \item\label{parsing:item:1}
            First, a set of blueprints is predicted for each token in the input sentence; the number of predicted blueprints per position is a hyperparameter.
            Each blueprint is transformed into a supertag by replacing its wildcard symbol with the position in the sentence it was predicted for.
            The confidence value for the prediction of each blueprint accompanies each supertag as weight.
        \item\label{parsing:item:2}
            The supertags are combined into a weighted grammar.
            A statistical parsing\todo{clearly distinguish statistical grammar parsing from the whole process} process for the grammar formalism is used to find derivations for the sequence of consecutive positions in the input sentence.
            If reranking is used, then this step yields a collection of \(k\) best derivation trees, where \(k \in \DN_+\) is a hyperparameter and \emph{best} refers to an endorelation on the weights (e.g.\@ lowest cost or highest probability).
            Otherwise, it yields \emph{a best} derivation.
        \item\label{parsing:item:3}
            The derivations are converted into constituent structures by evaluating the \abrv{dcp} compositions or (in the case of \abrv{lcfrs} supertags) assuming the nonterminals as inner nodes.
            These constituent structures are extended to constituent trees by adding predicted \abrv{pos} symbols and the tokens from the input sentence.
        \item\label{parsing:item:4}
            Lastly, a reranking approach is used to (re-)score the constituent trees and pick the best as a result.
            We use \emph{data-oriented parsing}, a precise statistical grammar formalism, as the final stage of a coarse to fine parsing approach \citep{CraSchBod16}.
    \end{enumerate}
    For step \ref{parsing:item:1}, we use a neural network to compute the prediction confidence for each blueprint at each position in the input sentence.
    % The training of these models is described in \cref{chapter:training}.
    The transformation from grammar derivations to constituent structures in step \ref{parsing:item:3} is part of the definitions in \cref{sec:grammar:lcfrs,sec:grammar:hybrid}.
    The remaining steps \ref{parsing:item:2} and \ref{parsing:item:4} are described in more detail in the following two sections.

    \begin{figure}
        \subfile{figures/parsing-overview.tex}
        \caption{\label{fig:parsing:overview}
            Illustration of the supertagging-based parsing process.
            Staggered gray boxes indicate sequences of objects, e.g.\@, the \emph{parsing} step yields a collection of derivation trees for the input sentence.
        }
    \end{figure}


    \subfile{parsing/dcp-parsing.tex}
    \subfile{parsing/reranking.tex}

    \ifSubfilesClassLoaded{%
        \printindex
        \bibliography{../refeferences.bib}%
    }{}
\end{document}
