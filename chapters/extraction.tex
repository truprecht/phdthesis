\documentclass[../document.tex]{subfiles}

\begin{document}
    \chapter{Lexical Grammar Extraction from Treebanks}
    This chapter deals with the extraction of supertag grammars from treebanks.
    Here, the term \emph{supertag grammar} is understood as an lexical instance of any grammar formalism where the only terminal symbol occurring in the rules is a wildcard, which will be denoted by \tn{*}.
    Each rule in the instance of such a formalism is called a \emph{supertag}.
    In this chapter, we will consider the three previously discussed formalisms: \abrv{lcfrs}, \abrv{dcp} and hybrid grammars.
    Beyond the previous definitions, there are two small extensions to \abrv{lcfrs} and \abrv{dcp}:
    \begin{compactenum}
        \item
            In the case of \abrv{lcfrs}, there is a boolean (i.e.\@ either it is present or not) label that accompanies each rule.
            It stores information from the lexicalization process and is needed to reverse the process in order to transform a derivation in the supertag grammar into a constituent tree.
        \item
            In the case of \abrv{dcp}, there is an integer value added to each rule.
            It will indicate the maximum fanout that is admissible during parsing.
    \end{compactenum}
    These extensions are considered an integral part of each supertag for the parsing process.
    Their purpose will be further discussed in \cref{sec:extraction:readoff,sec:extraction:guided}.
    These two additions will not be part in the case of instances of hybrid grammars, even though they are a combination of \abrv{lcfrs} and \abrv{dcp} grammars.

    There are two approaches for the extraction described in this chapter:
    \begin{compactenum}
        \item
            The process described in \cref{sec:extraction:readoff} first extracts a derivation in a simple \abrv{lcfrs} for each tree in a treebank.
            After that, the rules within each derivation are lexicalized by transporting the terminal symbols occurring in the leaves of the derivation into inner nodes.
            With the help of annotations that are added to the rules and nonterminals within the rules, this transportation is reversible.
        \item
            The extraction procedure described in \cref{sec:extraction:guided} first assigns a sentence position to each inner node of the constituent structure.
            In the following, it extracts a derivation of lexical grammar rules according to the positions assigned to the inner nodes in each subtree.
    \end{compactenum}

    \todo{Can the guided extraction be implemented for lexical lcfrs? -- the already existing marker `swapped` can be abused to give the transportation direction}
    \todo{describe some common topics: extracted grammar = set of all extracted rules, wildcard as terminal, sentence position as terminal during extraction}
    \todo{describe why binarization is a common topic for both extraction algorithms}
    \todo{discuss why we show both extractions if the first is an instance of the second: it is not that the guided extraction cannot be implemented for lcfrs rules + swapped annotation, but the different concept of transportation vs. guides}

    \section{Binarization} \todo{clearify the term binarization: construct constituent tree where each node has exactly 0 or 2 successors}
    In a treebank, we may encounter nodes in constituent trees with arbitrary amounts of successors.
    \todo{add an example of successor distributions in a treebank}
    Most grammar extraction procedures share the common property that they construct a rule for each inner node (or a set of inner nodes) in a constituent tree with the rank matching the number of successors of the node (or the sum of successor in the set of nodes).
    Usually it is desirable to obtain binary grammars, because the design of efficient parsing algorithms is more straightforward.
    And more importantly, these binary grammars can be constructed in such a way that rules contained in similar derivations are shared and allow more general derivations.
    This can be achieved by \deflab<binarization>[bin:markov]{markovization} and choosing appropriate \deflab<binarization>[bin:strat]{binarization strategies}, which has shown to improve the parsing quality and time. \citep{Son08,Cra12}
    There are also specific binarization strategies for \abrv{lcfrs} capable of minimizing the parsing complexity of the resulting grammar. \citep{Gil10}

    In the scope of this thesis, we view binarization as a preprocessing step for constituent trees rather than grammars.
    I.e.\@ it is an operation that transforms a given constituent tree into a \hyperlink{binctree}{binary} constituent tree such that it can be transformed back into the original constituent tree.
    The binarization process affords new constituent symbols that will appear in the place of nodes with one or more than two successors.
    The form of these additional symbols is determined by the chosen binarization strategy and markovization parameters.

    \subsection{Binarization Strategies}\todo{what exactly is a binarization strategy}
    The \deflab{binarization} of constituent structures removes and replaces nodes that have either one or more than two successors.
    These two cases are handled separately.

    All of the binarization strategies described in this section share the approach for dealing with chains of nodes having one successor:
    \begin{inparaenum}
        \item if the successor of the bottom-most node in the chain is an inner node, they are merged into this successor, or
        \item if the successor of the bottom-most node in the chain is a leaf, they are merged with the \abrv{pos} symbol for the leaf.
    \end{inparaenum}
    The merged symbols must not occur in the original alphabets of constituent and \abrv{pos} symbols, and must be unique for each sequence of merged constituent/\abrv{pos} symbols.
    Here, the merged nodes are denoted by concatenating the symbols interleaved by \cn{+}.
    E.g.\@ a chain of unary nodes ``\cn{root}'', ``\cn{s}'' that is merged with the \abrv{pos} symbol ``\cn{\$.}'' is the new symbol ``\cn{root+s+\$.}''.
    This approach of handling nodes with one successor is done after dealing with nodes with more than two successors.
    Because this is common among all binarization strategies, we view only the other case as an actual part of the strategies.

    Each node carrying \( n > 2 \) successors is split into \( n-1 \) binary nodes that are connected in some parent-child constellation.
    The topmost of these nodes will carry the label of the original node, each following is a new symbol (i.e.\@ the symbol must not be a constituent symbol in the original tree) determined by the binarization strategy.
    The strategy also dictates how each node is split and how the new nodes are connected.
    Because all binarization strategies are defined per-node, we will formalize each binarization strategy as a function that replaces the root node in a constituent tree (if has more than 2 successors) with a collection of binary nodes.
    The function is then called recursively to handle each subtree.

    The reversal of the binarization procedure is also independent of the strategy:
    \begin{compactenum}
        \item all binary nodes with symbols that were introduced by the binarization procedure are removed and their children are appended to their parent, and
        \item each node originating from a merge of unary nodes is expanded by replacing it with the chain of unary nodes, and
        \item each \abrv{pos} symbol originating from a merge is replaced by the trailing pos symbol and the sequence of unary nodes is inserted atop of the corresponding leaf in the constituent structure.
    \end{compactenum}

%    \begin{definition}
%        Let \(\varSigma, \varPi\) and \(\varGamma\) be some alphabets.
%        A binarization strategy \(b\) for \(\CT_{\varGamma \varPi \varSigma}\) defines
%        \begin{compactenum}
%            \item an alphabet of constituent symbols \(b(\varGamma)\),
%            \item an alphabet of \abrv{pos} symbols \(b(\varPi)\),
%            \item a function \(f\colon \CT_{\varGamma \varPi \varSigma} \to \CT_{b(\varGamma) b(\varPi) \varSigma}\) that transforms a constituent tree into a constituent tree with binary root, and
%            \item a partial function \(f^{-1} \colon \CT_{b(\varGamma) b(\varPi) \varSigma} \parto \CT_{\varGamma \varPi \varSigma}\) that reverses the transformation \(f\).
%        \end{compactenum}
%        The binarization operation, denoted just by \(b\), extends the function \(f\) such that \todo{formal definition is complicated, as we deal with constituent trees}
%    \end{definition}

    \paragraph{Left- or Right-Branching Factorization}
    These strategies replace each node with \( n>2 \) successors with a series of \( n-1 \) binary nodes.
    The \deflab<binarization!binarization strategies>[binarization:l2r]{right-branching factorization} constructs nodes such that
    \begin{itemize}
        \item the first (and top-most) node has the same symbol as the original node,
        \item for each \(2 \leq i \leq n-1\), the \(i\)-th node's symbol consists of the original node's symbol and the symbols of its rightmost \(n-i-1\) successors. Those symbols are denoted in the form \(\binnode{A}{B_i,B_{i+1},\ldots,B_n}\) where \(A\) is the root node and \(B_1, \ldots, B_n\) are its
        \item for each \(1 \leq i \leq n-2\), the left successor of the \(i\)-th node is the \(i\)-th successor of the original node, and its right successor is the \((i+1)\)-th constructed node, and
        \item the successors of the last (an bottom-most) node are the two rightmost successors of the original node.
    \end{itemize}
    The \deflab<binarization!binarization strategies>[binarization:r2l]{left-branching factorization} mirrors the right-branching strategy: It constructs a series of binary nodes connected via their left successors in the opposite direction.

    \paragraph{Head-Outward Binarization.}
    This \deflab<binarization!binarization strategies>[binarization:r2l]{head-outward binarization}[strategy] mixes left- and right-branching factorization depending on the successor that contains the head symbol of the node.
    If the node's head symbol is contained in its \(n\)-th successor, then
    \begin{enumerate}
        \item the first \(k-n\) (top-most) binary nodes are constructed according to the left-branching binarization strategy for the trailing \(k-n\) successors, and
        \item the remaining \(n-1\) binary nodes are constructed according to the right-branching strategy for the first \(n\) successors.
    \end{enumerate}
    In the resulting constituent tree, the head symbol is in the yield of the bottom-most constructed node.
    The motivation for choosing this strategy is that in bottom-up parsers the head symbol is processed first and determines the constituent symbol.
    There are distinct notations for the introduced top left-branching nodes and the bottom right-branching nodes to avoid ambiguities during parsing with the extracted grammars (which is pretty common in combination with markovization).
    In these notations, the left symbol \(\langle\) is doubled in left-branching nodes, and the right symbol \(\rangle\) is doubled in right-branching nodes.

    \paragraph{Minimizing Fanout or Parsing Complexity.}
    These two strategies replace non-binary nodes with a combination of new binary nodes such that an assessment function for the resulting tree is minimized.
    In the \deflab<binarization!binarization strategies>[bin:minfo]{minimal fanout binarization}[first case], this function coincides with the occurring fanouts.
    In the \deflab<binarization!binarization strategies>[bin:minpc]{minimal parsing complexity binarization}[latter case], it is a combination of the the parsing complexity and fanout.
    In contrast to the previous binarization strategies, these two may not only scramble the order of the successors in the constructed subtrees, but also construct branches of intermediate nodes in both directions.
    As the two previous strategies, the symbols at the constructed nodes contain the parent constituent symbol and the constituent symbol of the processed successors.

    \begin{figure}
        \todo[inline]{beispiel für binarisierung einfügen}
        \caption{\label{fig:ex:binarization}
            Comparing different binarization strategies, in order from left to right: right-branching, left-branching factorization, head-outward binarization, minimal fanout and minimal parsing complexity binarization.}
    \end{figure}

    \subsection{Head-Inward Ternarization: Not Quite Binarization} \label{sec:extraction:bin:hi}
%    The strategy to binarize constituent trees head-outward takes account of the head assignment for each inner node of the constituent structure.
%    For each node of rank \(\ge 2\), it produces a series of nodes such that the child containing the head is attached to the bottom-most node.
    \todo[inline]{ist das nötig? die Struktur der Ableitung sollte ausschließlich vom Guide abhängen.}


    \subsection{Markovization}
    The symbols introduced by all binarization strategies contain the symbol of the substituted node \(A\) and the symbols in the successors \(B_1, \ldots, B_k\) below these (intermediate) nodes.
    They are chosen such that there are represent an intermediate state in parsing the original non-binary rule.

    Markovization is an extension to the binarization strategies that changes the constructed labels such that they contain only the symbols of the last \(h\) successors that were recently processed.
    The value \(h\) is called the \emph{horizontal markovization window} and is considered a parameter for the binarization.
    With very large values for \(h\), the symbols are unchanged to the formulation in the binarization strategy.
    If the value for \(h\) is chosen small, this generalizes the symbols such that they are common in binarized constituent trees where nodes with the same symbol and similar successors were binarized.
    In the edge case of \(h=0\), there is no information about the children and all symbols constructed during the binarization of node with the same symbol are the same.

    Additional to the horizontal window \(h\), there is a \emph{vertical context} \(v\) that may add information from the parent symbols for each node in the constituent tree (and not just the nodes introduced during the binarization).
    With values greater than 1, the last \(v-1\) parents are added to each node in the constituent structure.
    The additions are denoted without ambiguity, such that they can be easily removed and the original constituent tree is obtained.
    Here, a sequence of additional parent symbols are denoted by concatenating them, interleaved by ``\cn{$\wedge$}'', to the right of the symbol.

    \begin{figure}
        \todo[inline]{beispiel oben im vgl. mit Markovisierung einfügen}
        \caption{\label{fig:ex:markovization}
            Comparing two constituent trees and their binarized forms with markovization parameters \(v=2\) and \(h=0\).}
    \end{figure}


    \section{Extracting Lexical \abrv{Lcfrs}} \label{sec:extraction:readoff}
    The extraction procedure in this section was introduced by \citet{RupMoe21}.
    It is based on simple \abrv{lcfrs} read-off from treebanks as shown by \citet{KalMai13} followed by a per-tree lexicalization inspired by the procedures presented by \citet{EngMalMan18, MoeRup20}.
    During the extraction, each constituent tree in the treebank is first binarized and a derivation of simple binary lcfrs rules is constructed for it (described in \cref{sec:extraction:readoff:simple}).
    I.e.\@ only the rules occurring at the leaves in the derivations contain terminal symbols.
    Each derivation consisting of simple \abrv{lcfrs} rules is transformed into a derivation of lexical rules by \emph{transporting} terminal symbols from the leaf rules into inner nodes (described in \cref{sec:extraction:readoff:lex}).
    \todo{discuss the form of lcfrs supertags: the swapped label is nor necessary if the transportation direction can be inferred from the rest of the rule. E.g. with a transportation as def. by the strict guide it were regular lcfrs rules.}

    \subsection{Reading-off Simple LCFRS Rules}\label{sec:extraction:readoff:simple}\todo{title: treebank grammars}
    The extraction of statistical \abrv{lcfrs} from treebanks was formulated by \citet{MaierSogaard08} and extends the concept of context-free treebank grammar studied by \citet{Cha96}.
    Such treebank grammars are essentially read of from each constituent tree in a treebank by defining a non-lexical rule for each inner node of the tree with its symbol as \abrv{lhs} nonterminal and its successors (or the corresponding \abrv{pos} symbols if we encounter leaves) as \abrv{rhs} nonterminals.
    The compositions are defined according to the yield of the node and the yields of its successors.
    Lastly, lexical, nullary rules are defined such that the \abrv{pos} symbol is the \abrv{lhs} and the composition contains exactly the token at the same position in the sentence.
    The grammar is usually put into a statistical framework where a probability is induced for each rule counting the occurrences in the treebank where it was read-off.
    The probabilities are normalized according to the \abrv{lhs} nonterminal.

    \todo{formalize read-off rules, especially the composition functions}
    \todo{example constituent tree $\rightarrow$ derivation}

    \subsection{Lexicalizing \abrv{Lcfrs} Derivations}\label{sec:extraction:readoff:lex}
    The lexicalization scheme is based on \citet{MoeRup20}.
    However, we ignore all weights and perform lexicalization on individual derivations rather than on a grammar induced from the entire treebank.
    More specifically, we directly read off a set of lexical rules from each tree in the treebank; then the union of these rules forms our uni-lexical LCFRS $\lexG$.
    In contrast to that, \citet{MoeRup20} first induce an LCFRS $G$ from the entire treebank and then lexicalize $G$.
    Thus $\lexG$ may have a different language than the lexicalization of $G$.

    We obtain a set of uni-lexical rules from each tree $t$ in the treebank by the following procedure.
    \begin{enumerate}
        \item Binarize the tree.
        The symbol $|$ is appended to constituents that result from binarization (this reflects Markovization with a vertical context of $1$ and a horizontal context of $0$).
        \label[step]{step:binarize}
        \item Transform the tree into an LCFRS derivation using the standard technique for induction of LCFRS \cite{MaierSogaard08}.
        \label[step]{step:induce}
        \item Collapse every chain of monic rules; the nonterminals of each chain are combined to a new nonterminal.
        \label[step]{step:dechain}
        \item Remove every terminating rule that has a parent and insert the terminal from its composition into the parent.%
        \label[step]{step:fuseterm}%
        \item Propagate terminals from double-lexical terminating rules into non-lexical branching rules.
        All rules in the resulting derivation are lexical.
        \label[step]{step:propterm}
        \item Split all remaining double-lexical terminating rules into two uni-lexical rules.
        All rules in the resulting derivation are uni-lexical.
        The resulting derivation is called $d_{\mathrm{lex}}(t)$.
        \label[step]{step:split}
        \item Read off the rules of $d_{\mathrm{lex}}(t)$; call them $R(t)$.
        \label[step]{step:readoff}
    \end{enumerate}

    These steps are defined such that in the LCFRS formed by $R(t)$, $d_{\mathrm{lex}}(t)$ is a derivation for the sentence of $t$.
    Moreover, we are able to reconstruct $t$ from $d_{\mathrm{lex}}(t)$ by reverting \crefrange{step:split}{step:binarize} (we will give the details later).

    Finally, we obtain the uni-lexical LCFRS $\lexG$ by combining the rules $R(t)$ for each tree $t$.
    The initial nonterminals of $\lexG$ are all left-hand sides of roots of $d_{\mathrm{lex}}(t)$.

    Let $t$ be a tree in the treebank.
    \Cref{step:binarize,step:induce} and their reversal are standard techniques for trees and LCFRS.
    After applying them to $t$, we obtain an LCFRS derivation in which each occurring rule is either of the form
    \begin{itemize}[nosep]
        \item \(A \to (\sigma)\), where $\sigma$ is a terminal and \(A\) is the part-of-speech tag of $\sigma$,
        \item \(A \to c(B_1)\) where \(\fanout(A) = \fanout(B)\) and \(c = \id_{\fanout(A)}\), or
        \item \(A \to c (B_1, B_2)\) where \(c\) contains no terminals and none of \(B_1, B_2\) is an initial nonterminal.
    \end{itemize}
    Let us denote this derivation by $d$.

    In the following, we describe \crefrange{step:dechain}{step:split} of the above procedure in more detail (showing examples in \crefrange{fig:dechain}{fig:split}) and also glimpse at how the individual steps are reverted.


    \paragraph{\Cref{step:dechain}.}
    We \emph{repeatedly} replace parts in \(d\) of the form
    \(A \to c (B) \big( B \to c' \big) \) by \( A\text+B \to c' \), and
    \(A \to c (B) \Big( B \to c'(C_1, C_2) \big( \ldots \big) \Big) \) by \( A\text+B \to c' (C_1, C_2) \big( \ldots \big) \),
    until there is no monic rule in \(d\) left.
    If the occurrence of \(A \to c (B)\) is not the root of \(d\), then the corresponding nonterminal in the parent's rhs is replaced by \(A\text+B\).\footnote{
        Note that root nodes in the derivation may be collapsed, this is why we use LCFRS with \emph{multiple} initial nonterminals.
    }
    After this step, there are only branching rules and terminating rules in \(d\).
    \Cref{fig:dechain} shows an example for this step.

    This step is easy to reverse, as the composition of every removed rule is $c = \id_{\fanout(B)}$.
    We give the formal description in \cref{unlex:dechain}.

    \paragraph{\Cref{step:fuseterm}.}
    We remove every non-root occurrence $r$ of a terminating rule $A \to (\sigma)$ in $d$.
    Let $r$ be the $i$th child of its parent (with $i \in [2]$), then we replace the parent's composition $c$ by $\sem{c}_i(\sigma)$ and remove the $i$th nonterminal in the parent's rhs.

    %We replace all occurrences in \(d\) of the form
    %\begin{itemize}
    %  \item \(A \to c(B_1, B_2) \Big(B_1 \to (\sigma_1), B_2 \to (\sigma_2)\Big)\) by \(A \to \sem{c}(\sigma_1, \sigma_2)\),
    %  \item \(A \to c(B_1, B_2) \Big(B_1 \to (\sigma_1), \ldots \Big)\) by \(A \to \sem{c}_1(\sigma_1)\,(B_2)\Big( \ldots \Big)\), and
    %  \item \(A \to c(B_1, B_2) \Big(\ldots, B_2 \to (\sigma_2) \Big)\) by \(A \to \sem{c}_2(\sigma_2)\,(B_1)\Big( \ldots \Big)\).
    %\end{itemize}
    We note that the parent becomes lexical, and after this step, every rule in $d$ is either branching or lexical.
    Moreover, every terminal rule in $d$ is either double-lexical (if both children were removed) or the root of \(d\) (and thus its only node).
    \Cref{fig:fuseterm} shows an example for this step.

    Clearly, this step loses information, namely the left-hand sides of the removed rules.
    These nonterminals are part-of-speech tags (that may be enriched with nonterminals of collapsed monic rules from the previous step).
    For the reversal of this step, we opted to predict them along with the supertags as part of the supertagger.
    The formal description of the reversal is given in \cref{unlex:fuseterm}.

    \paragraph{\Cref{step:propterm}.}
    For each occurrence \(r\) of a branching rule $A \to c(A_1, A_2)$ in \(d\), let us consider the occurrence \(t\) of the leftmost terminating rule (i.e.\@ \(t\) is a leaf) that is reachable via the second successor of \(r\).
    For example, in \cref{fig:propterm:pre}, the two binary rules (\(r\)) are end points of gray arrows; these arrows start at the mentioned leaves (\(t\)).
    Our goal is to remove one terminal from $t$ and propagate it all the way up to $r$.
    For this, at each node \(s\) on the path from \(t\) to \(r\) (from bottom up):
    \begin{itemize}[nosep]
        \item If \(s\) is \(t\), we remove the leftmost terminal in the rule's composition at \(s\).
        \item
        If \(s\) is neither \(t\) nor \(r\), we insert the last removed terminal right before the variable \(\x_1\) and then remove the leftmost terminal in the rule's composition at \(s\).

        We note that if the rule at $s$ is monic and the variable $\x_1$ occurs right of the terminal in its composition, then we propagate a different terminal than the one received from the child.
        In order to be able to reverse this step, we need to remember whether the terminal in the rule's composition stayed the same or was swapped with the terminal received from the child.
        In the following, we consider this information as part of the rule (cf.\@ the gray annotation \textsuperscript{swapped} in \cref{fig:propterm}).
        \item If \(s\) is \(r\), we insert the last removed terminal right before the variable \(\y_1\) in the rule's composition at \(s\).
    \end{itemize}
    If \(s \neq r\), let \(s'\) be the parent of $s$ and $s$ the \(i\)th child of $s'$.
    If, after removal of a terminal at \(s\), the first component in the composition is empty:
    \begin{itemize}[noitemsep,topsep=1pt]
        \item we annotate the lhs nonterminal at \(s\) and the \(i\)th rhs nonterminal at \(s'\) with $^-$ and remove the empty component, and
        \item if \(i = 1\) (resp.\@ \(i = 2\)), we remove \(\x_1\) (resp.\@ \(\y_1\)) and replace every other occurrence of \(\x_i\) by \(\x_{i-1}\) (resp.\@ \(\y_j\) by \(\y_{j-1}\)) at $s'$.
    \end{itemize}
    Otherwise, we annotate the nonterminals with \(^+\).

    We note that the rule at $r$ is uni-lexical and branching now, the rule at \(t\) is uni-lexical and terminating, and the number of terminals in each rule between them did not change.
    After this step, every rule in $d$ is lexical.
    \Cref{fig:propterm} shows an example for this step.

    There is a suitable leaf $t$ for every branching rule $r$.
    Intuitively, this holds since (a) after \cref{step:fuseterm} every leaf of $d$ is a double-lexical rule and (b) for each branching rule we first go to its second successor and then follow the path of first successors until we reach a leaf.
    Here, (a) guarantees that there exists a double-lexical rule for each branching rule and (b) guarantees that a terminal in each double-lexical rule is transported to at most one branching rule, thus at most one terminal is removed from it.
    We refer the more interested reader to consult the proof of correctness by \citet{EngMalMan18};
    this proof also applies to our method.

    The reversal of this step removes all annotation ($^+$, $^-$, and \textsuperscript{swapped}) and restores each composition in $d$ to its original form.
    We note that the original composition can be obtained deterministically; the construction is given in \cref{unlex:propterm}.

    \paragraph{\Cref{step:split}.}
    We replace the rightmost terminal $\sigma_2$ in the composition of each double-lexical terminating rule by a variable and add a new nonterminal $A^{\text{R}}$ to the rule's right-hand side (making it a uni-lexical monic rule).
    Then we insert the rule $A^{\text{R}} \to (\sigma_2)$ as a child.
    %Each occurrence of the form
    %  \(A \to (\sigma_1 \sigma_2)\) is replaced by \(A \to (\sigma_1 \x_1) (A^\text{R}) \Big(A^\text{R} \to (\sigma_2)\Big)\), and
    %  \(A \to (\sigma_1, \sigma_2)\) is replaced by \(A \to (\sigma_1, \x_1) (A^\text{R}) \Big(A^\text{R} \to (\sigma_2)\Big)\),
    %where \(A^\text{R}\) is a new nonterminal.
    After this step, every rule in $d$ is uni-lexical.
    \Cref{fig:propterm:post,fig:split} show an example for this step.
    The reversal of this step is straightforward.
    %We formally describe it in \cref{unlex:split}.


    \section{Guided Extraction} \label{sec:extraction:guided}
    In the evaluation of supertagging with lexical \abrv{lcfrs} according to the extraction in the previous section, it was already noted that the extracted sets of supertags were rather large and their prediction less accurate compared to other publications in the field. \cite{RupMoe21}
    In this section, we focus on a generalization of the extraction of lexical grammar rules as introduced by \citet{Rup22} that were investigated with the aim to tackle these two issues.
    The generalization deals with the following two limitations of the process described in the previous section:
    \begin{compactenum}
        \item
            Constructing lexical LCFRS rules picked a sentence position for each inner node of the constituent structure according to a fixed strategy.\todo{link to the subsection/paragraph}
            Such a strategy is now formalized by a \emph{guide} that maps each inner node position of a constituent structure to sentence position in its yield.
            The concept is generalized by introducing multiple strategies to define guides for a given constituent structure, which are called \emph{guide constructors}.
        \item
            LCFRS rules were constructed with constituent symbols as nonterminals, which were then supplemented with annotations during the lexicalization process.
            This section decouples the nonterminals from the other extraction processes and introduce multiple strategies to define them, called \emph{nonterminal constructors}.
    \end{compactenum}
    To implement the two generalizations, the extraction described in this section will produce \abrv{dcp} and hybrid grammars.
    \todo{describe the different formalisms: supertags as tuples with lcfrs rules <-> hybrid grammar rules}

    \subsection{Guides and Guide Constructors}
    The concept of guides for the extraction was introduced by \citet{Rup22}.
    In that publication, a guide is a function \(\varphi\) that assigns a sentence position to each inner node position \(\rho\) of a binary constituent structure \(\xi\) such that
    \begin{inparaenum}
        \item \(\varphi(\rho)\) is in the yield below the position \(\yield(\xi|_\rho)\), and
        \item \(\varphi\) is injective, i.e.\@ each sentence position is assigned to at most one inner node position.
    \end{inparaenum}
    As \(\xi\) is binary, there is exactly one sentence position that is not assigned to any inner node.
    During the grammar extraction process, that constructs a rule for each inner node position in the constituent structure, the guide is used to determine the lexical symbol in the rule.
    Intuitively, it can be seen to assign a ``responsibility'' for each inner node by a sentence position.
    The remaining sentence position is handled by a special rule that produces no constituent node.

    In this thesis, we will generalize the guide concept by relaxing the second condition: each sentence position may be mapped to multiple inner node positions in the constituent structure.
    This allows us to define rules that produce multiple constituent nodes.
    \todo[inline]{
        The concept can be generalized further: decouple the guides in to two, a lexical decomposition for the string grammar derivation and a guide that constructs the tree grammar.
        That would be able to derive hybrid grammars with, for example, strictly-inorder guided string derivations and head-driven \abrv{dcp} functions.
    }
    We will use this in \cref{sec:extraction:guided:head} to derive lexical grammars for constituent structures that are inspired by those extracted for dependency parsing.
    They are extracted such that each rule contains a lexical symbol in tandem with each inner node position of the constituent structure that it is a head of.

    \begin{definition}[Guide]
        Let \(\xi\) be an indexed tree.
        The function \(\varphi\colon \npos(\xi) \to \yield(\xi)\) is called \emph{guide for \(\xi\)} if, for each \(\rho \in \npos\)
        \begin{inparaenum}[(i)]
            \item \(\varphi(\rho) \in \yield(\xi|_\rho)\), and
            \item if there is any child position \(\rho' \in \npos(\xi)\) of \(\rho\) with \(\varphi(\rho) = \varphi(\rho')\), then each position \(\omega\) between \(\rho\) and \(\rho'\) has the same value \(\varphi(\rho) = \varphi(\omega) = \varphi(\rho')\).
        \end{inparaenum}
        \(\guide(\xi)\) denotes the set of all guides for the indexed tree \(\xi\).
    \end{definition}

    The second constraint in the definition ensures that there are no intermediate nodes assigned to a different position between an ancestor and an antecedent position in the constituent structure.
    So the guide may only assign the same leaf to connected node positions.

    \begin{example}
        Consider the constituent structure \(\xi\) illustrated in the bottom figure.
        The gray encircled integers shown next to each inner node give the value of a guide \(\varphi\) for the node's position.
        For example \(\varphi(\varepsilon) = \varphi(1) = \varphi(1\,1) = 3\).
        The leaves 0, 1 and 5 are not assigned to any inner node position.

        \begin{center}
          \subfile{figures/guides/example-constituents.tex}
        \end{center}
    \end{example}

    \begin{definition}[Guide Constructor]
        Let \(\varSigma\) be an alphabet of constituent symbols and \(T \subseteq \itrees^\varSigma\) be some subset of indexed trees.
        A guide constructor for \(T\) is a function \(\varPhi\colon T \to (\DN^* \parto \DN)\) such that for each indexed tree \(\xi \in T\), the partial function \(\varPhi(\xi)\) is a guide constructor for \(\xi\).
    \end{definition}

    In the following, we will give the instances for guide constructors that were investigated by \citet{Rup22} plus one additional instance (\emph{headed guide}).

    \paragraph{Vanilla Guide Constructor.}
    This guide constructor aims to formalize the assignment of lexical items to inner nodes that is achieved by the transportation in the extraction of lexical \abrv{lcfrs} rules described in the previous section.
    A guide produced by this constructor maps each node position either to the leftmost leaf that is a direct successor, or (if not available) to the leftmost leaf in the yield of its right successor.
    The assignment is determined for each node from top to bottom.
    It is formally defined as follows:\todo{the first and second cases are not mutually exclusive}
    \[
        \mathrm{van}(\xi)(\rho) = \begin{cases}
            \min L_\rho & \text{if $L_\rho \neq \emptyset$} \\
            \mathrm{van}(\xi)(\rho \cdot 1) & \text{if $|\children(\rho) \cap \npos(\xi)| = 1$} \\
            \min_{i \in \yield(\rho\cdot 2)} i &\text{otherwise}
        \end{cases}
    \]
    Where the set \(L_\rho\) denotes the leaves just below a node that were not assigned to an ancestor node:
    \[
        L_\rho = \{\xi(\rho) \in \yield(\xi) \mid \rho \in \lpos(\xi) \cap \children(\rho) \} \setminus \{\mathrm{van}(\xi)(\rho') \in \yield(\xi) \mid \rho' \in \ancestors(\rho)\}
    \]

    \paragraph{Strict Guide Constructor.}
    This is a small adjustment of the vanilla guide constructor that removes the special case where an inner node is assigned to a leaf below it.
    A guide constructed by it maps each inner node of rank \(\ge 2\) to the least leaf of the second successor.
    Each inner node of rank 1 assumes the assignment of its child.
    Formally, it is defined as follows:
    \[
        \mathrm{strict}(\xi)(\rho) = \begin{cases}
            \mathrm{van}(\xi)(\rho \cdot 1) & \text{if $|\children(\rho) \cap \npos(\xi)| = 1$} \\
            \min_{i \in \yield(\rho\cdot 2)} i &\text{otherwise}
        \end{cases}
    \]

    \paragraph{Least and Near Guide Constructors.}
    These two guides were developed with the intention to
    \begin{inparaenum}
        \item assign as few nodes as possible to leaves that are not direct children, and
        \item assign many nodes to leaves that are as close as possible.
    \end{inparaenum}
    Both of those intentions are pretty similar, but may exclude each other in certain cases.\todo{example}
    The leaf for each inner position is determined in both cases via a breadth-first search for the first leaf that was not assigned to
    \begin{inparaenum}
        \item a descendant node (the assignment is determined bottom-up), or
        \item an antecedent node (the assignment is determined top-down), respectively.
    \end{inparaenum}
    This is formalized in the equation
    \[
        g(\xi)(\rho) = \xi\big( \min^{\unlhd} \: \big\{\rho' \in \descendants(\rho) \cap \lpos(\xi) \mid \xi(\rho') \notin L_\rho \big\} \big)
    \]
    where \(\unlhd\) is the total ordering of tree positions according to breadth-first search and set \(L_\rho\) keeps track of the previously assigned leaves.
    The total order \(\unlhd \subseteq \DN^* \times \DN^*\) is defined such that \(\rho \unlhd \tau\) if and only if \(|\rho| < |\tau|\) or \(|\rho| = |\tau| \land \rho <^* \tau\).
    In case
    \begin{inparaenum}
        \item it excludes all assigned leaves below \(\rho\) from the breadth-first search:
            \(L_\rho = \{ g(\xi)(\rho') \in \yield(\xi) \mid \rho' \in \descendants(\rho) \cap \npos(\xi) \}\); in case
        \item it excludes all leaves assigned to nodes above \(\rho\):
            \(L_\rho = \{ g(\xi)(\rho') \in \yield(\xi) \mid \rho' \in \ancestors(\rho) \cap \npos(\xi) \}\).
    \end{inparaenum}

    Whereas the previous constructors were defined solely according to the constituent structure, the remaining two take some additional linguistic information into account: heads and modifiers.
    This also requires a special treatment with respect to binarization which is applied to the constituent structures for the two following guide constructors.
    This is explained further within the following paragraphs.

    \paragraph{Head Guide Constructors.}
    As the name suggests, these guides assign the head position to each inner node of the constituent structure.
    This implements an intuitive approach to deal with the relation between the inner nodes and their assigned head position: For each lexical symbol, there will be a lexical rule that contains the information to produce exactly the inner nodes it is head of.
    Naturally, this requires that the constituent structure is equipped with the necessary head assignment.
    And we have to keep in mind, that there is no sensible head assignment for binarized constituent trees in general.
    Therefore, we limit the this guide constructor to the cases of plain (i.e.\@ unbinarized) or head-inward ternarized (cf.\@ \cref{sec:extraction:bin:hi}) constituent trees.

    \paragraph{Modifier Guide Constructors.}
    Modifier guides aim to offer leaf assignments that complement head-outward binarized constituent structures.
    They assign the head of a modifier to each inner node in the constituent structure.
    We consider these guides only for head-outward binarized constituent structures, as there is exactly one modifier for each inner node.

    \subsection{Nonterminal Constructors}
    A \emph{nonterminal constructor} computes a lhs nonterminal for the grammar rule included in each supertag.
    Each of the following constructors computes a nonterminal for the position \(\rho\) in \(\xi\) from the constituent symbol \(\xi(\rho)\), the set of leaves \(\yield(\xi|_\rho)\) below \(\rho\) and the set of leaves \(L\) assigned by \(\guide\) to the ancestors of \(\rho\).
    We omit the fanout subscripts if they are \(1\).
    We give examples using the \emph{shortest guide}, as shown in \cref{fig:constituent:bin}, for the root position \(\varepsilon\) where \(\xi(\varepsilon) = \text{SBAR+S}\), \(\yield(\xi|_\varepsilon) = \{0,\ldots,5\}\) and \(L = \emptyset\) and the position \(1.1\) of the bottom VP node where \(\xi(1.1) = \text{VP}\), \(\yield(\xi|_{1.1}) = \{0,4,5\}\), \(L = \{0,3\}\) and \(\fanout(\yield(\xi|_{1.1}) \setminus L) = 1\).

    \paragraph{Vanilla Nonterminals.}
    The nonterminal consists of the symbol \(\xi(\rho)\), the fanout \(\fanout(\yield(\xi|_\rho))\) as subscript, and if \(L\) contains any leaf in \(\yield(\xi|_\rho)\), then the difference in fanout \(\fanout(\yield(\xi|_\rho) \setminus L) - \fanout(\yield(\xi|_\rho))\) as superscript.
    This superscript indicates the difference in fanout at \(\rho\) in the original constituent tree compared to the leaves assigned to the nodes in the subtree at \(\rho\) by the guide.
    (At most one leaf is assigned to an ancestor of \(\rho\).)
    In our two examples, we construct the nonterminals \(\text{SBAR+S}\) and \(\text{VP}_2^{-1}\)

    \paragraph{Classic Nonterminals.}
    The nonterminal consists of the first symbol\footnote{
           After merging unary nodes in step (i) of the extraction, each node may consist of multiple constituent symbols.}
    in \(\xi(\rho)\) (including markers introduced during binarization) and the fanout \(\fanout(\yield(\xi|_\rho) \setminus L)\) as subscript.
    This constructor omits annotations that depend on the guide and is more akin to usual strategies in LCFRS extraction \cite{MaierSogaard08}.
    For our examples, the nonterminals are \(\text{SBAR}\) and \(\text{VP}\).

    \paragraph{Coarse Nonterminals.} Like the \emph{classic} nonterminals, but we replace the constituent symbols occurring in the treebank by their first letter.
    This is a very rough approximation of nonterminals in coarse-to-fine parsing \cite{Cha06} that does not need a specific clustering for each treebank.
    For our examples, the nonterminals are \(\text{S}\) and \(\text{V}\).

    \subsection{Extraction Algorithm}
    The process described in this section is used to extract a sequence of supertags, one for each word in a sentence, from a given constituent tree.
    We distinguish four steps (i--iv) which are executed consecutively.
    The parameters for steps (i--iii) are described in detail in the next section.

%    \begin{figure}
%        \centering
%        \includestandalone{figures/example-constituents-bin}
%        \caption{\label{fig:constituent:bin}
%            Constituent structure and pos symbols after binarization (\(v=1\), \(h=0\); ho and lr binarization coincide) of \cref{fig:constituent}.
%            The symbol ``VP\!\texttt{|\!<\!>}'' was introduced during binarization; former unary nodes were joined by ``+''.
%            Gray integers next to inner nodes show the leafs assigned by a guide for the constituent structure.
%            %        The guides were defined using the guide constructors from \cref{sec:con:para} in the following order: vanilla (plain), strict (rectangle), modifier (diamond), least (circle), shortest (pentagon).
%        }
%    \end{figure}

    \paragraph{(i) Binarization.}
    We construct a binary constituent tree with the usual strategies in constituent parsing \cite{KalMai13}:
    Each unary node is merged with its child (or pos symbol, if the child is a leaf), and nodes with arity \(n>2\) are split into \(n-1\) binary nodes according to the parameters described in \cref{sec:con:para}.
    After this step, the constituent tree for a sentence \(w\) is equipped with \(|w|-1\) inner nodes.
    \Cref{fig:constituent:bin} shows a binary tree resulting from binarization of the tree in \cref{fig:constituent}.

    \paragraph{(ii) Guide.}
    In this step, we define a \emph{guide} for the binary constituent structure \(\xi\), i.e.\@ a mapping \(\guide\) between inner node positions and leaves in the constituent structure.
    In the following step, a lexical LCFRS rule will be constructed for the constituent at each inner node and the assigned leaf.
    Intuitively, the guide determines which sentence position is ``responsible'' for the constituent at each position.
    Formally, a guide for \(\xi\) is an injective function \(\guide\colon \npos(\xi) \to \yield(\xi)\) such that, for each \(\rho \in \npos(\xi)\), the assigned leaf \(\guide(\rho)\) is in \(\yield(\xi|_\rho)\).
    \Cref{fig:constituent:bin} shows a guide for our example constituent structure, assigning a leaf (illustrated in gray circles) to each inner node.
    As \(\guide\) is injective and there is one less inner node than leaves in \(\xi\), there is exactly one leaf that is not in the image of \(\guide\).
    We will investigate multiple strategies, called \emph{guide constructors}, to define guides for a given constituent tree as discussed in \cref{sec:con:para}.

    \paragraph{(iii) Lexical rule induction.}
    In this step, we will construct a lexical LCFRS rule \(r'\) and the components \(c\), \(t\) and \(p\) of the supertag for each leaf in the constituent structure.
    The nonterminals in the rule are determined by a chosen hyperparameter \(\ntcon\), called the \emph{nonterminal constructor}, in terms of the constituent symbol and the guide \(\guide\) as described in \cref{sec:con:para}.
    We give examples for (the root position in) the tree in \cref{fig:constituent:bin}, the guide values shown in pentagons (shortest guide constructor) and constituent symbols as nonterminals (classic nonterminal constructor).

    We start with the leaf \(i'\) that is not in the image of \(\guide\) and define a new nonterminal \(\text{L-}A\) using the fixed string ``L-'' and the nonterminal \(A\) produced by \(\ntcon\) for the parent of \(i'\).
    In that case \(c = t = \text{None}\), \(p = \mathit{pos}(i')\), and \(r' = \text{L-}A \to [i']\).
    In \cref{fig:constituent:bin}, the leaf \(i'=2\) is not in the image of \(\guide\), it yields \(r' = \text{L-NP} \to [2]\), and \(p = \text{NN})\).

    After that, we define the following for each position \(\rho \in \npos(\xi)\) (from bottom up) and its assigned leaf \(i = \guide(\rho)\):
    \begin{asparaitem}
        \item
        The LCFRS rule \(r'\) is assembled in the usual manner from \(i\) as lexical symbol and variables for the spans formed by the leaves in each successor except those leaves that are assigned by \(\guide\) to \(\rho\)'s ancestors.
        \(\ntcon\) produces the lhs nonterminal for \(\rho\), the rhs nonterminals are the lhs nonterminals constructed for \(\rho\)'s children.
        In our example, \(r\) is assembled from the lexical symbol \(3\), the left successor's leaves are \(\{\underline{0\vphantom{,}}_{(x_1)}, \underline{4,5} _{(x_2)}\}\) and the right one's are \(\{\underline{1,2} _{(y_1)}\}\);
        hence \(r = \text{S} \to [x_1 \, y_1 \, 3 \, x_2] (\text{VP}_2, \text{NP})\).

        \item
        \(t\) is \emph{None} if the leaf \(\guide(\rho)\) is a direct child of \(\rho\), otherwise it is the index among the children where \(\guide(\rho)\) is located.
        In our example, 3 is not a child of the root, it is in its first successor; therefore \(t=1\).

        \item
        \(c\) is \(\xi(\rho)\) if it was not introduced during binarization (i.e.\@ the symbol \(\xi(\rho)\) does not contain some markers \texttt{|<..>}), otherwise it is None.
        In our example, \(c = \text{SBAR+S}\).

        \item
        \(p\) is the pos symbol at \(\guide(\rho)\) in \(\mathit{pos}\).
        In our example \(p = \text{VBD}\).
    \end{asparaitem}

    \paragraph{(iv) Supertag extraction.}
    The tuples constructed in the previous step closely resemble supertags as described in the previous subsection.
    We pull them from the constructed tree and order them according to the sentence position included in the lexical rule.
    Lastly, the sentence position in each rule is replaced by a wildcard symbol ``\_''.

    \ifSubfilesClassLoaded{%
        \printindex
        \bibliography{../references}%
    }{}
\end{document}
